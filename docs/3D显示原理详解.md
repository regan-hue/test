# Cornerstone.js 3D 医学影像显示原理详解

## 目录
1. [DICOM 数据基础](#1-dicom-数据基础)
2. [从 2D 切片到 3D 体积](#2-从-2d-切片到-3d-体积)
3. [多平面重建（MPR）原理](#3-多平面重建mpr原理)
4. [Cornerstone.js 渲染架构](#4-cornerstonejs-渲染架构)
5. [代码实现详解](#5-代码实现详解)
6. [为什么需要排序](#6-为什么需要排序)
7. [WebGL 渲染原理](#7-webgl-渲染原理)
8. [Crosshairs 工具原理](#8-crosshairs-工具原理)
9. [完整数据流总结](#9-完整数据流总结)
10. [关键技术点总结](#10-关键技术点总结)
11. [常见问题](#11-常见问题)
12. [参考资料](#12-参考资料)

---

## 1. DICOM 数据基础

### 1.1 什么是 DICOM？

DICOM（Digital Imaging and Communications in Medicine）是医学影像的标准格式。每个 DICOM 文件包含：

1. **图像数据**：像素值（通常是 12 位或 16 位灰度）
2. **元数据（Tags）**：包含患者信息、扫描参数、空间位置等

### 1.2 关键的 DICOM Tags

在我们的代码中，使用了以下关键 Tags：

```javascript
// ImagePositionPatient (0020,0032)
// 格式: "x\\y\\z" - 图像在患者坐标系中的 3D 位置
// 例如: "-125.5\\-125.5\\-100.0"
// 这告诉我们这张切片在 3D 空间中的精确位置

// SliceLocation (0020,1041)
// 切片的相对位置（毫米），用于排序

// InstanceNumber (0020,0013)
// 图像的序列号，备用排序依据
```

### 1.3 为什么需要这些信息？

医学影像扫描通常产生**一系列 2D 切片**，每张切片代表身体的一个横截面。要重建 3D 体积，我们需要知道：
- 每张切片在 3D 空间中的位置
- 切片之间的间距
- 切片的朝向（方向向量）

---

## 2. 从 2D 切片到 3D 体积

### 2.1 数据流程

```
DICOM 文件（2D切片）
    ↓
[获取元数据] → ImagePositionPatient, SliceLocation
    ↓
[排序] → 按照空间位置排序
    ↓
[构建体积] → 将 2D 切片堆叠成 3D 体积数据
    ↓
[存储] → 3D 体积数组（voxel data）
    ↓
[渲染] → 通过 WebGL 渲染到屏幕
```

### 2.2 体积数据结构

3D 体积数据在内存中的组织方式：

```javascript
体积数据 = {
  dimensions: [width, height, depth],  // 例如: [512, 512, 200]
  spacing: [xSpacing, ySpacing, zSpacing],  // 例如: [0.5, 0.5, 1.0] 毫米
  origin: [x, y, z],  // 体积的起始位置
  direction: [[1,0,0], [0,1,0], [0,0,1]],  // 方向矩阵
  scalarData: Uint16Array,  // 实际的像素值数组
  // scalarData 的大小 = width × height × depth
}
```

### 2.3 Voxel（体素）概念

- **Pixel（像素）**：2D 图像的最小单位
- **Voxel（体素）**：3D 体积的最小单位，可以理解为"3D 像素"

每个 voxel 包含：
- 位置：(x, y, z) 坐标
- 值：灰度值（0-4095 或 0-65535）

---

## 3. 多平面重建（MPR）原理

### 3.1 什么是 MPR？

MPR（Multi-Planar Reconstruction）是从 3D 体积数据中提取任意平面的技术。

### 3.2 三个标准视图

#### 轴向视图（Axial）
```
从上往下看（Z 轴方向）
┌─────────────┐
│             │
│   头部      │  ← 这是你看到的
│             │
└─────────────┘
```

#### 矢状视图（Sagittal）
```
从侧面看（X 轴方向）
┌─────┐
│     │
│ 头  │  ← 这是你看到的
│ 部  │
└─────┘
```

#### 冠状视图（Coronal）
```
从前面看（Y 轴方向）
┌─────────┐
│   头部   │  ← 这是你看到的
│         │
└─────────┘
```

### 3.3 MPR 如何工作？

1. **定义平面**：指定一个平面（通过法向量和点）
2. **采样**：从 3D 体积中提取该平面的像素值
3. **插值**：由于平面可能不正好对齐 voxel，需要进行插值
4. **渲染**：将采样结果渲染为 2D 图像

### 3.4 插值算法

当平面不正好对齐 voxel 时，使用**三线性插值**（Trilinear Interpolation）：

```
要获取位置 (x, y, z) 的值：
1. 找到周围的 8 个 voxel
2. 根据距离加权平均
3. 得到平滑的像素值
```

---

## 4. Cornerstone.js 渲染架构

### 4.1 核心组件

```
┌─────────────────────────────────────┐
│      RenderingEngine                │  ← 渲染引擎（管理所有视口）
│  ┌──────────┐  ┌──────────┐        │
│  │ Viewport │  │ Viewport │  ...  │  ← 视口（每个显示一个视图）
│  └──────────┘  └──────────┘        │
└─────────────────────────────────────┘
           │              │
           ▼              ▼
    ┌──────────┐    ┌──────────┐
    │  Volume  │    │  Volume  │     ← 体积数据（3D数据）
    └──────────┘    └──────────┘
           │              │
           ▼              ▼
    ┌──────────┐    ┌──────────┐
    │ WebGL    │    │ WebGL    │     ← WebGL 渲染器
    │ Context  │    │ Context  │
    └──────────┘    └──────────┘
```

### 4.2 Volume Loader 的工作流程

```javascript
// 1. 创建体积加载器
const volume = await volumeLoader.createAndCacheVolume(volumeId, {
  imageIds,  // 图像ID列表（已排序）
})

// 2. 内部处理流程：
// a) 加载第一张图像，获取元数据（尺寸、间距等）
// b) 创建 3D 数组缓冲区
// c) 并行加载所有图像
// d) 将每张图像的数据放入对应的位置
// e) 构建体积对象
```

### 4.3 Streaming Volume Loader

为什么使用 `cornerstoneStreamingImageVolumeLoader`？

1. **流式加载**：不需要等待所有图像加载完成
2. **按需加载**：只加载当前视图需要的切片
3. **内存效率**：可以处理大型数据集（数千张切片）

---

## 5. 代码实现详解

### 5.1 步骤 1：获取和排序图像

```javascript
async function fetchInstances() {
  // 1. 从 Orthanc 获取实例列表
  const instanceIds = seriesData.Instances || []
  
  // 2. 获取每个实例的元数据
  const instancesWithMetadata = await Promise.all(
    instanceIds.map(async (instanceId) => {
      const tags = await fetch(`/instances/${instanceId}/tags?simplify`)
      // 提取 ImagePositionPatient
      const imagePositionPatient = tags['0020,0032']
      // 解析为 [x, y, z] 坐标
      const position = imagePositionPatient.split('\\').map(Number)
      return { instanceId, position, ... }
    })
  )
  
  // 3. 按照 Z 坐标排序（轴向位置）
  instancesWithMetadata.sort((a, b) => {
    return a.position[2] - b.position[2]  // Z 坐标排序
  })
  
  // 4. 构建 imageIds
  return instancesWithMetadata.map(item => 
    `wadouri:/instances/${item.instanceId}/file`
  )
}
```

**为什么这样做？**
- Orthanc 返回的顺序可能是随机的
- 必须按照空间位置排序，才能正确构建 3D 体积
- Z 坐标代表轴向位置（从头到脚）

### 5.2 步骤 2：创建体积

```javascript
async function loadVolume(renderingEngine, viewportIds, imageIds) {
  // 1. 创建体积ID（唯一标识符）
  const volumeId = `cornerstoneStreamingImageVolume:volume-${seriesInstanceUID}`
  
  // 2. 创建并缓存体积
  const volume = await volumeLoader.createAndCacheVolume(volumeId, {
    imageIds,  // 已排序的图像ID列表
  })
  
  // 3. 加载体积数据
  await volume.load()
  // 内部过程：
  // - 加载第一张图像，获取尺寸、间距等元数据
  // - 创建 3D 数组（例如：512 × 512 × 200）
  // - 并行加载所有图像
  // - 将每张图像的数据放入对应位置
}
```

**内部发生了什么？**

```javascript
// Cornerstone.js 内部伪代码
class StreamingImageVolume {
  async load() {
    // 1. 加载第一张图像
    const firstImage = await loadImage(imageIds[0])
    
    // 2. 获取元数据
    const { width, height } = firstImage
    const depth = imageIds.length
    const spacing = calculateSpacing(imageIds)  // 计算切片间距
    
    // 3. 创建 3D 数组
    this.scalarData = new Uint16Array(width * height * depth)
    
    // 4. 加载所有图像
    await Promise.all(imageIds.map(async (imageId, index) => {
      const image = await loadImage(imageId)
      // 将图像数据复制到 3D 数组的对应位置
      const offset = index * width * height
      this.scalarData.set(image.pixelData, offset)
    }))
  }
}
```

### 5.3 步骤 3：创建视口

```javascript
const viewportInputArray = [
  {
    viewportId: 'axial-viewport',
    type: Enums.ViewportType.ORTHOGRAPHIC,  // 正交投影
    element: axialViewport.value,  // DOM 元素
    defaultOptions: {
      orientation: Enums.OrientationAxis.AXIAL,  // 轴向方向
    },
  },
  // ... 其他视图
]

renderingEngine.setViewports(viewportInputArray)
```

**ViewportType.ORTHOGRAPHIC 是什么意思？**

- **正交投影**：平行投影，没有透视效果（适合医学影像）
- 与透视投影不同，正交投影保持物体大小不变

### 5.4 步骤 4：设置体积到视口

```javascript
const axialViewport = renderingEngine.getViewport(viewportIds.axial)
axialViewport.setVolumes([{ volumeId }])
```

**发生了什么？**

1. 视口获取体积引用
2. 根据视口的 `orientation`（轴向/矢状/冠状），计算采样平面
3. 从 3D 体积中提取该平面的数据
4. 通过 WebGL 渲染到 Canvas

### 5.5 步骤 5：渲染

```javascript
renderingEngine.renderViewports([viewportIds.axial, ...])
```

**渲染流程：**

```
1. 对于每个视口：
   a) 计算当前平面的位置和方向
   b) 从 3D 体积中采样该平面
   c) 应用窗宽窗位（Window/Level）
   d) 转换为 RGBA 颜色
   e) 通过 WebGL 渲染到 Canvas
```

---

## 6. 为什么需要排序

### 6.1 问题场景

假设我们有 3 张切片，Orthanc 返回的顺序是：
```
实例1: Z = 100mm  (头部)
实例2: Z = 50mm   (中部)
实例3: Z = 0mm    (脚部)
```

如果**不排序**，直接构建体积：
```
体积数组索引: [0, 1, 2]
实际位置:     [100mm, 50mm, 0mm]
```

这会导致：
- 头部显示在底部
- 脚部显示在顶部
- 图像顺序完全错乱

### 6.2 排序后的结果

排序后（按 Z 坐标）：
```
体积数组索引: [0, 1, 2]
实际位置:     [0mm, 50mm, 100mm]  ← 正确顺序
```

### 6.3 排序算法

```javascript
instancesWithMetadata.sort((a, b) => {
  // 优先使用 ImagePositionPatient 的 Z 坐标
  if (a.position && b.position) {
    const zDiff = a.position[2] - b.position[2]
    if (Math.abs(zDiff) > 0.001) {  // 容差处理浮点数误差
      return zDiff
    }
  }
  
  // 备用：使用 SliceLocation
  if (a.sliceLocation !== null && b.sliceLocation !== null) {
    return a.sliceLocation - b.sliceLocation
  }
  
  // 最后：使用 InstanceNumber
  return a.instanceNumber - b.instanceNumber
})
```

**为什么需要容差（0.001）？**
- 浮点数比较可能有精度误差
- 两张切片可能非常接近但不完全相同

---

## 7. WebGL 渲染原理

### 7.1 为什么使用 WebGL？

1. **性能**：GPU 加速，可以实时渲染大型 3D 数据
2. **并行处理**：可以同时处理数百万个 voxel
3. **硬件加速**：利用显卡的强大计算能力

### 7.2 渲染管线

```
3D 体积数据
    ↓
[顶点着色器] → 定义几何形状（平面）
    ↓
[片段着色器] → 对每个像素：
    1. 计算该像素在 3D 空间中的位置
    2. 从体积数据中采样（三线性插值）
    3. 应用窗宽窗位转换
    4. 转换为颜色值
    ↓
[帧缓冲区] → 最终图像
    ↓
Canvas 显示
```

### 7.3 窗宽窗位（Window/Level）

医学影像的像素值是**原始灰度值**（例如：0-4095），需要转换为屏幕颜色（0-255）。

```javascript
// 窗宽窗位转换伪代码
function windowLevelTransform(pixelValue, windowWidth, windowLevel) {
  const min = windowLevel - windowWidth / 2
  const max = windowLevel + windowWidth / 2
  
  if (pixelValue < min) return 0      // 黑色
  if (pixelValue > max) return 255    // 白色
  
  // 线性映射到 0-255
  return ((pixelValue - min) / windowWidth) * 255
}
```

**为什么需要窗宽窗位？**
- 不同组织有不同的密度范围
- 通过调整窗宽窗位，可以突出显示特定组织
- 例如：骨窗、肺窗、软组织窗

### 7.4 三线性插值

当平面不正好对齐 voxel 时：

```javascript
// 伪代码：三线性插值
function trilinearInterpolation(volume, x, y, z) {
  // 1. 找到周围的 8 个 voxel
  const x0 = Math.floor(x), x1 = x0 + 1
  const y0 = Math.floor(y), y1 = y0 + 1
  const z0 = Math.floor(z), z1 = z0 + 1
  
  // 2. 获取这 8 个 voxel 的值
  const v000 = volume.getVoxel(x0, y0, z0)
  const v001 = volume.getVoxel(x0, y0, z1)
  // ... 其他 6 个
  
  // 3. 三线性插值
  const dx = x - x0, dy = y - y0, dz = z - z0
  
  // 先沿 Z 轴插值
  const c00 = v000 * (1 - dz) + v001 * dz
  const c01 = v010 * (1 - dz) + v011 * dz
  const c10 = v100 * (1 - dz) + v101 * dz
  const c11 = v110 * (1 - dz) + v111 * dz
  
  // 再沿 Y 轴插值
  const c0 = c00 * (1 - dy) + c01 * dy
  const c1 = c10 * (1 - dy) + c11 * dy
  
  // 最后沿 X 轴插值
  return c0 * (1 - dx) + c1 * dx
}
```

---

## 8. Crosshairs 工具原理

### 8.1 什么是 Crosshairs？

Crosshairs（交叉线）是在三个视口中显示的十字线，用于标识当前位置。

### 8.2 工作原理

```
用户在轴向视口中点击位置 (x, y)
    ↓
计算该点在 3D 空间中的位置 (x, y, z)
    ↓
在矢状视口中：显示垂直线（固定 X 坐标）
在冠状视口中：显示水平线（固定 Y 坐标）
在轴向视口中：显示十字线（当前 Z 坐标）
```

### 8.3 坐标转换

```javascript
// 伪代码：视口坐标 → 3D 世界坐标
function viewportToWorld(viewport, x, y) {
  // 1. 获取视口的相机参数
  const camera = viewport.getCamera()
  
  // 2. 计算射线（从相机位置到点击位置）
  const ray = viewport.getRayFromScreen(x, y)
  
  // 3. 与当前平面相交
  const intersection = ray.intersectPlane(currentPlane)
  
  return intersection  // 3D 世界坐标
}

// 3D 世界坐标 → 其他视口的屏幕坐标
function worldToViewport(viewport, worldPos) {
  const camera = viewport.getCamera()
  const screenPos = camera.project(worldPos)
  return screenPos
}
```

### 8.4 同步机制

```javascript
// 当用户在视口 A 中移动时：
toolGroup.on('tool-activation', (event) => {
  const { viewportId, worldPos } = event
  
  // 更新所有视口的 Crosshairs 位置
  toolGroup.viewports.forEach(viewport => {
    if (viewport.id !== viewportId) {
      // 计算该视口中应该显示的位置
      const screenPos = worldToViewport(viewport, worldPos)
      viewport.setCrosshairsPosition(screenPos)
    }
  })
})
```

---

## 9. 完整数据流总结

```
1. DICOM 文件（Orthanc 服务器）
   ↓
2. 获取实例列表和元数据
   ↓
3. 按空间位置排序
   ↓
4. 构建 imageIds 列表
   ↓
5. 创建 Volume Loader
   ↓
6. 加载所有图像，构建 3D 体积数组
   ↓
7. 创建三个 Viewport（轴向/矢状/冠状）
   ↓
8. 每个 Viewport 从 3D 体积中采样平面
   ↓
9. 应用窗宽窗位转换
   ↓
10. WebGL 渲染到 Canvas
    ↓
11. 显示在浏览器中
```

---

## 10. 关键技术点总结

### 10.1 为什么使用 Streaming Volume Loader？

- **内存效率**：不需要一次性加载所有数据
- **性能**：可以处理数千张切片
- **用户体验**：渐进式加载，更快显示

### 10.2 为什么需要 SharedArrayBuffer？

- **多线程**：Web Worker 可以共享内存
- **性能**：避免数据复制，提高解码速度
- **要求**：需要特定的 HTTP 头（COOP/COEP）

### 10.3 为什么使用 WebGL？

- **GPU 加速**：实时渲染大型 3D 数据
- **并行处理**：同时处理数百万个像素
- **硬件优化**：利用显卡的强大计算能力

### 10.4 为什么需要排序？

- **空间一致性**：确保体积数据按正确顺序组织
- **MPR 正确性**：错误的顺序会导致错误的平面重建
- **用户体验**：避免图像错乱

---

## 11. 常见问题

### Q1: 为什么图像显示是黑白的？

A: 医学影像通常是灰度图像。窗宽窗位用于调整对比度，突出显示不同组织。

### Q2: 为什么需要三个视口？

A: 三个视口提供三个正交视图，帮助医生从不同角度理解解剖结构。

### Q3: 体积数据占用多少内存？

A: 例如：512 × 512 × 200 切片，16 位（2 字节）：
```
512 × 512 × 200 × 2 = 104,857,600 字节 ≈ 100 MB
```

### Q4: 为什么使用 wadouri 协议？

A: WADO-URI 是 DICOM 标准协议，用于直接访问 DICOM 文件。Orthanc 支持此协议。

### Q5: dicom-parser 是什么？

A: `dicom-parser` 是一个 JavaScript 库，用于解析 DICOM 文件的二进制格式。它能够：
- 读取 DICOM Tags（元数据）
- 解析像素数据
- 处理各种 DICOM 数据类型

在我们的代码中，`dicom-parser` 被传递给 `cornerstoneDICOMImageLoader`，用于解析从服务器获取的 DICOM 文件。

---

## 12. 参考资料

- [Cornerstone.js 官方文档](https://www.cornerstonejs.org/)
- [DICOM 标准](https://www.dicomstandard.org/)
- [WebGL 教程](https://webglfundamentals.org/)
- [医学影像处理基础](https://en.wikipedia.org/wiki/Medical_imaging)
- [dicom-parser GitHub](https://github.com/cornerstonejs/dicom-parser)

---

## 结语

本文档详细解释了从 DICOM 文件到 3D 显示的完整流程。关键点：

1. **数据组织**：2D 切片 → 3D 体积
2. **空间排序**：确保正确的空间关系
3. **MPR 重建**：从 3D 体积提取任意平面
4. **WebGL 渲染**：高效的 GPU 加速渲染
5. **交互工具**：Crosshairs 实现多视图同步

理解这些原理有助于：
- 调试问题
- 优化性能
- 扩展功能
- 理解医学影像处理的基础知识

---

**文档版本**: 1.0  
**最后更新**: 2024年11月

